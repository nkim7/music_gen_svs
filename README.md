# Educationalâ€¯Songâ€¯Compositionâ€¯withâ€¯LLMsâ€¯&â€¯Synthesisedâ€¯Vocals

> **Bachelorâ€¯Project â€” Ã‰coleâ€¯Polytechniqueâ€¯FÃ©dÃ©raleâ€¯deâ€¯Lausanne (EPFL) Â· CHILI Lab**
> **Author:** *Nagyungâ€¯Kim*Â Â Â 
> Project codeâ€‘name: **LLMâ€‘Poweredâ€¯Educationalâ€¯Songwriting**

---

## ðŸ“– Overview

This project automates the creation of **childrenâ€‘friendly educational songs**.
From a twoâ€‘word prompt (*mood*Â +Â *topic*), the pipeline delivers in **<â€¯60â€¯seconds**:

* GPTâ€‘generated **lyrics** & **chord loop**
* MIDI **melody + accompaniment**
* AIâ€‘sung **vocal track** (OpenUtauâ€¯Ã—â€¯DiffSinger)
* **PDF lead sheet** and fullyâ€‘mixed **WAV** file

The system targets teachers and pupils alike: teachers can illustrate new concepts without musical expertise, while pupils can explore composition interactively via a chatbot or survey interface.

---

## ðŸ§© Architecture at a Glance

```
â”Œâ”€ React Native App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mood + topic                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼ REST (Flask)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1Â Â·Â Prompt Handler (GPTâ€‘4o)                  â”‚
â”‚   â†³ tempo Â· 8â€‘chord cycle                   â”‚
â”‚                                              â”‚
â”‚ 2Â Â·Â Choose Model                             â”‚
â”‚   A) static melody Â· dynamic lyrics          â”‚
â”‚   B) static lyrics  Â· dynamic music          â”‚
â”‚                                              â”‚
â”‚ 3Â Â·Â LyricsÂ &Â SyllableÂ Balancer               â”‚
â”‚ 4Â Â·Â midi_gen â†’ melody & accompaniment        â”‚
â”‚ 5Â Â·Â ust_gen  â†’ USTX (phoneme fixes)          â”‚
â”‚ 6Â Â·Â OpenUtau (WORLDLINEâ€‘R) â†’ vocal.wav       â”‚
â”‚ 7Â Â·Â FluidSynth + pydub â†’ stems & final mix   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
  Chatbot Â Â or Â Â Survey âžœ iterative refinement
```

---

## ðŸ”¬ Two Generation Modes

| Mode  | What StaysÂ Fixed | What Varies | IdealÂ For                 | Key Tradeâ€‘offs                                      |
| ----- | ---------------- | ----------- | ------------------------- | --------------------------------------------------- |
| **A** | Melody           | Lyrics      | short, highâ€‘quality songs | Lyric length must be shoeâ€‘horned to melody (slower) |
| **B** | Lyrics           | Music       | longer, fast turnaround   | Music risk of repetition; pauses in sparse text     |

> *Empirical benchmark*: ModelÂ B keeps generation time almost flat as lyric length grows, while ModelÂ A time rises linearly but yields more polished music for â‰¤â€¯8 lines.

---

## ðŸš€ QuickÂ Start

```bash
# clone & install
$ git clone https://github.com/<yourâ€‘fork>/educationalâ€‘songâ€‘llm.git
$ cd educationalâ€‘songâ€‘llm
$ python -m venv .venv && source .venv/bin/activate
$ pip install -r requirements.txt

# generate in one go
$ python main.py "happy" "bears"

# or via REST
$ python api_server.py &
$ curl -X POST http://localhost:5000/generate-music -H "Content-Type: application/json" \
       -d '{"mood":"calm","topic":"rainforests"}'
```

Outputs are written to `music/gen/demo_outputs/` and `final_music/` (WAV, MIDIs, USTX, PDF).

---

## ðŸ“± Frontâ€‘End Highlights

* **Input screen** â†’ mood & topic fields
* **Playback screen** â†’ lyrics card, waveform seek/loop, stems toggle
* **Chatbot** â†’ relevance checking, sentiment, fun facts, emoji cues
* **Survey** â†’ 1â€‘tap Likert + freeâ€‘text; CSV export for classroom analytics

Younger children (â‰ˆâ€¯7â€¯y) preferred the concise **Survey**; older kids (10â€¯â€“â€¯14â€¯y) spent more time and reported higher enjoyment with the **Chatbot** mode.

---

## ðŸ›  Requirements (tested)

| Tool          | Version                           |
| ------------- | --------------------------------- |
| Python        | 3.10Â 64â€‘bit                       |
| Node / npm    | â‰¥Â 18 / 9                          |
| OpenAI API    | GPTâ€‘4o access                     |
| FluidSynth    | 2.3 + FluidR3\_GM.sf2             |
| MuseScore CLI | 3.x                               |
| OpenUtau      | 0.1.529 + **Hanamiâ€¯VCCVâ€‘EN** bank |
| WindowsÂ 10/11 | GUI automation (`uiautomation`)   |

---

## ðŸ“Š Results Snapshot

* **Generation time** (RTXÂ T4, 16 bars) â€” 50â€¯s average.
* **User study** (nâ€¯=â€¯4) â€” Chatbot mode preferred by older children; survey faster for younger pupils.
* **Audio quality** â€” DiffSinger shallow diffusion + phoneme offset hacks yielded noticeably clearer *it's / that's* articulation.

See full evaluation in the *Report* PDF (docs/).
Benchmarks reproduced in `/notebooks/`.

---

## ðŸ”® Roadmap

* Simplify chatbot language & add TTS for preâ€‘readers.
* Expand instrument palette & vocal styles.
* Accept **voice or drawing** prompts to seed songs.
* Replace bruteâ€‘force syllable balancer with dynamic programming to cut latency.

---

## ðŸ“œ License & Citation

Code released under **MIT**; thirdâ€‘party models retain their own licenses.

Please cite if you use this work:

```bibtex
@bachelorthesis{kim2025educSongLLM,
  title  = {Educational Song Composition using Large Language Models with Synthesised Vocal Singing},
  author = {Kim, Nagyung and Tozadore, Daniel},
  school = {EPFL â€” CHILI Lab},
  year   = {2025}
}
```

---

Made with â˜•Â + âœ¨ in Lausanne.
